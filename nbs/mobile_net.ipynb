{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd \n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "# Ignore warnings \n",
    "import warnings \n",
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "# Import pathlib\n",
    "from pathlib import Path\n",
    "\n",
    "# Interactive mode on \n",
    "plt.ion() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Device: 1\n",
      "Current Device Name: TITAN V\n",
      "Current Device Specs: _CudaDeviceProperties(name='TITAN V', major=7, minor=0, total_memory=12066MB, multi_processor_count=80)\n"
     ]
    }
   ],
   "source": [
    "from torch import cuda\n",
    "\n",
    "cuda.set_device(0)\n",
    "current_dev = cuda.current_device()\n",
    "current_dev_name = cuda.get_device_name(current_dev)\n",
    "current_dev_specs = cuda.get_device_properties(current_dev)\n",
    "\n",
    "print(f'Current Device: {current_dev}')\n",
    "print(f'Current Device Name: {current_dev_name}')\n",
    "print(f'Current Device Specs: {current_dev_specs}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeatMapsDataset(Dataset):\n",
    "    '''\n",
    "    Dataset for network flow heatmaps\n",
    "    Args:\n",
    "        @root (Path): path to root directory for dataset  \n",
    "        @transforms (callable, optional): transforms to be applied to data\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, root: Path, transform=None):\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        self.classes = ['ddos_tcp', 'clean_tcp']\n",
    "        self.images = []\n",
    "        for dirent in self.classes:\n",
    "            tmp = self.root / dirent\n",
    "            self.images += [x for x in tmp.iterdir() if x.suffix.lower() == '.png']\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images[idx]\n",
    "        image = io.imread(img_path)\n",
    "        image = image[:23, :23, :3]\n",
    "        \n",
    "        label = str(self.images[idx].parents[0])\n",
    "        label = label.split('/')[-1]\n",
    "        \n",
    "        sample = (image, label)\n",
    "        \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "    '''\n",
    "    Converts an image to a tensor\n",
    "    Args:\n",
    "        @sample (ndarray, string): image in the form of a numpy array and it's label \n",
    "    '''\n",
    "    def __call__(self, sample):\n",
    "        image, label = sample\n",
    "        \n",
    "        image = image.transpose((2, 0, 1))\n",
    "        return (torch.from_numpy(image), label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path.cwd().parents[0] / 'data' / 'heat_maps'\n",
    "\n",
    "composed = transforms.Compose([\n",
    "    ToTensor()\n",
    "])\n",
    "\n",
    "data = HeatMapsDataset(path, transform=composed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 23, 23])\n",
      "(23, 23, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f5de612b9b0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = data[0][0]\n",
    "print(img.shape)\n",
    "img = img.numpy().transpose((1, 2, 0))\n",
    "print(img.shape)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(data, batch_size=4, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showBatch(batch):\n",
    "    '''Show a batch of images and their labels'''\n",
    "    \n",
    "    image_batch, label_batch = batch\n",
    "    batch_size = len(image_batch)\n",
    "    grid_border_size = 2\n",
    "    \n",
    "    grid = utils.make_grid(image_batch)\n",
    "    \n",
    "    plt.imshow(grid.numpy().transpose((1, 2, 0)))\n",
    "    \n",
    "    for label in label_batch:\n",
    "        print(label, end='\\t')\n",
    "    print()\n",
    "    \n",
    "    plt.title('Batch from dataloader')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_tcp\tclean_tcp\tclean_tcp\tclean_tcp\t\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i_batch, sample_batched in enumerate(loader):\n",
    "    img, label = sample_batched\n",
    "    \n",
    "    if i_batch == 23:\n",
    "        plt.figure()\n",
    "        showBatch(sample_batched)\n",
    "        plt.axis('off')\n",
    "        plt.ioff()\n",
    "        plt.show()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/SGF.EDUBEAR.NET/eam96/.cache/torch/hub/pytorch_vision_v0.4.2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MobileNetV2(\n",
       "  (features): Sequential(\n",
       "    (0): ConvBNReLU(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "    (1): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (4): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (8): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (9): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (10): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (11): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (12): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (13): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (14): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (15): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (16): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (17): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (18): ConvBNReLU(\n",
       "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.2, inplace=False)\n",
       "    (1): Linear(in_features=1280, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.hub.load('pytorch/vision:v0.4.2', 'mobilenet_v2', pretrained=False, num_classes=2)\n",
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-c895f7a8c472>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m ])\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mimg_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'path' is not defined"
     ]
    }
   ],
   "source": [
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "img_set = ImageFolder(path, transform=preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img_set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-5d7d761dbc98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'img_set' is not defined"
     ]
    }
   ],
   "source": [
    "plt.imshow(img_set[0][0].numpy().transpose((1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img_set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-7ec056c32d2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0minput_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0minput_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'img_set' is not defined"
     ]
    }
   ],
   "source": [
    "input_tensor = img_set[0][0]\n",
    "input_batch = input_tensor.unsqueeze(0)\n",
    "input_batch = input_batch.to('cuda')\n",
    "model.to('cuda')\n",
    "\n",
    "input_batch.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    output = model(input_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5383, 0.4617], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(torch.nn.functional.softmax(output[0], dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data for model\n",
    "path = Path.cwd().parents[0] / 'data' / 'heat_maps'\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "img_set = ImageFolder(path, transform=preprocess)\n",
    "trainloader = DataLoader(img_set, batch_size=4, num_workers=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MobileNet hyperparameters \n",
    "num_epochs = 2\n",
    "eta = 0.001\n",
    "nu = 0.9\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=eta, momentum=nu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    10] loss: 0.570\n",
      "[1,    20] loss: 0.696\n",
      "[1,    30] loss: 0.454\n",
      "[1,    40] loss: 0.715\n",
      "[2,    10] loss: 0.552\n",
      "[2,    20] loss: 0.315\n",
      "[2,    30] loss: 0.381\n",
      "[2,    40] loss: 0.272\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data[0].to('cuda'), data[1].to('cuda')\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 10 == 9:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 10))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data for model\n",
    "path = Path.cwd().parents[0] / 'data' / 'heat_maps'\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "img_set = ImageFolder(path, transform=preprocess)\n",
    "testloader = DataLoader(img_set, batch_size=len(img_set), num_workers=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape: torch.Size([174, 3, 224, 224])\n",
      "Output Shape: torch.Size([174, 2])\n",
      "Output: 1 \tExpected: 1\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 1 \tExpected: 1\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 1 \tExpected: 1\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 1 \tExpected: 1\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 1 \tExpected: 1\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 1 \tExpected: 1\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 1 \tExpected: 1\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 1 \tExpected: 1\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 1 \tExpected: 1\n",
      "Output: 1 \tExpected: 1\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 1 \tExpected: 1\n",
      "Output: 1 \tExpected: 1\n",
      "Output: 1 \tExpected: 1\n",
      "Output: 1 \tExpected: 1\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 1 \tExpected: 1\n",
      "Output: 1 \tExpected: 1\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 1 \tExpected: 1\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 1 \tExpected: 1\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 1 \tExpected: 1\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 1 \tExpected: 1\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 1 \tExpected: 1\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 1 \tExpected: 1\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 1 \tExpected: 1\n",
      "Output: 1 \tExpected: 1\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 1 \tExpected: 1\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 1 \tExpected: 1\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 1 \tExpected: 1\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 1 \tExpected: 1\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 1 \tExpected: 1\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 1 \tExpected: 1\n",
      "Output: 1 \tExpected: 1\n",
      "Output: 1 \tExpected: 1\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 1 \tExpected: 1\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 1 \tExpected: 1\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 1 \tExpected: 1\n",
      "Output: 1 \tExpected: 1\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 1 \tExpected: 1\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 1 \tExpected: 1\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 1 \tExpected: 1\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Output: 0 \tExpected: 0\n",
      "Accuracy on test data: 100.0\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for i, data in enumerate(testloader, 0):\n",
    "        inputs, labels = data[0].to('cuda'), data[1].to('cuda') \n",
    "\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        print(f'Input Shape: {inputs.shape}')\n",
    "        print(f'Output Shape: {outputs.shape}')\n",
    "\n",
    "        correct, total = 0, outputs.shape[0]\n",
    "        for output, label in zip(outputs, labels):\n",
    "            hypothesis = output.max(0)[1].item()\n",
    "            print(f'Output: {hypothesis} \\tExpected: {label}')\n",
    "            \n",
    "            if hypothesis == label: correct += 1\n",
    "                \n",
    "        print(f'Accuracy on test data: {(correct/total)*100}')\n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(174, 174)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct, total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
